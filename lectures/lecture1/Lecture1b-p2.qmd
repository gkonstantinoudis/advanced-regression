---
title: "Advanced Regression: Linear and generalised linear models II"
date: "02-21-2025"
author:
  name: "Garyfallos Konstantinoudis"
institute: "Imperial College London"
editor: visual
date-format: medium
title-slide-attributes:
  data-background-color: "#f3f4f4"
  data-background-image: "../../assets/logo_trans.png"
  data-background-size: 50%
  data-background-position: 90% 120%
format:
    revealjs:
      theme: [default, ../../assets/style.scss]
      logo: "../../assets/logo_trans.png"
      slide-number: true
      incremental: false
      chalkboard:
        buttons: false
---

## **Learning Objectives**

After this session students should be able to:

-   Understand generalised linear model (GLM) terminology

-   Distinguish between key distributions such as binomial, poisson, or beta

-   Employ and interpret diagnostic checks of model fit

-   Practically apply these models to actual data using R

## Generalised linear model

-   Basic definition

-   Technical details on exponential families and GLMs

-   Logistic regression and binary outcomes

-   Generalised linear models in R

:::: {style="font-size:90%;"}
## Generalised linear model (GLM)

-   Linear models can only model a quantitative outcome.

-   Quantitative outcomes are defined as a real number, taking possible values from $-\inf$ to $+\inf$.

-   Many important data types can by definition not be modelled using a linear model:

    -   Dichotomous or binary $\rightarrow$ only takes two values, 0 or 1

    -   Counts $\rightarrow$ only positive integers (0,1,2,3,...)

::: {.callout-note icon="false"}
Flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. Residuals are an important quantity for model diagnostics.
:::
::::

## Binary outcome and logistic regression

Example: Case-control study

$$
y_i =
\begin{cases}
1, \text{ If subject $i$ is a case} \\
0, \text{ If subject $i$ is a control} \\
\end{cases}
$$

```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
#| fig-align: "center"
#| warning: false
#| message: false

library(lars)
library(dplyr)
library(ggplot2)

data(diabetes)
x <- as.data.frame.matrix(diabetes$x)
y <- ifelse(diabetes$y > mean(diabetes$y), 1, 0)

ggplot() +
  geom_point(data = data.frame(x = x$glu, y = y), aes(x = x, y = y), size = 2) +
  theme_bw() +
  ylim(c(-0.5, 1.5)) +
  ylab("light/severe diabetes") +
  xlab("glucose level") +
  theme(text = element_text(size = 20))
```

::: {style="font-size: 70%;"}
## Binary outcome and logistic regression

$$y = \underbrace{\alpha + \beta x}_{\text{Linear predictor}} + \epsilon$$

-   Linear predictor: $\eta=\alpha + \beta x$ is defined from $-\inf$ to $+\inf$.

-   But $y$ only $0$ or $1$ $\rightarrow$ The linear regression do not match the data well.

```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
#| fig-align: "center"
#| warning: false
#| message: false

library(lars)
library(dplyr)
library(ggplot2)

data(diabetes)
x <- as.data.frame.matrix(diabetes$x)
y <- ifelse(diabetes$y > mean(diabetes$y), 1, 0)

coefs <- lm(y ~ glu, data = x) %>% coef()

ggplot() +
  geom_point(data = data.frame(x = x$glu, y = y), aes(x = x, y = y), size = 2) +
  geom_abline(intercept = coefs[1], slope = coefs[2], lwd = 1.3, col = "red") +
  theme_bw() +
  ylim(c(-0.5, 1.5)) +
  ylab("light/severe diabetes") +
  xlab("glucose level") +
  theme(text = element_text(size = 20))
```
:::

## How should we model this data?

**Key idea 1:** Instead of modelling the outcomes ($y=0$ or $y=1$) directly, logistic regression models the probability for $y=1$ denotes as

-   $P(y=1 \mid x)$

Notes on probabilities for binary data:

-   Probabilities can take values from 0 to 1

-   Probabilities are symmetric: $P(y=1\mid x) = 1- P(y=0\mid x)$

::: {style="font-size: 90%;"}
## How should we model this data?

**Key idea 2:** Transform the linear predictor $\eta= \alpha + \beta x_{i}$ (quantitative, can take values from $-\inf$ to $-inf$) to lie in the Interval $[0,1]$, which is valid for probabilities.

This can be achieved using the logit function: $\text{logit}(p) = \log (p/(1-p))$

```{r}
#| echo: false
#| eval: true
#| fig-width: 5
#| fig-height: 3
#| fig-align: "center"
#| warning: false
#| message: false

library(ggplot2)

set.seed(11)
p <- runif(n = 1000)

data.frame(
  p = p,
  logitp = log(p / (1 - p))
) %>%
  ggplot() +
  geom_line(aes(x = p, y = logitp), lwd = 1) +
  theme_bw() +
  theme(text = element_text(size = 15))
```
:::

## Logistic regression

\begin{align}
\text{logit}(P(y=1 \mid x)) &= \log(P(y=1 \mid x))/(1-P(y=1)\mid x) \\ &= \alpha + \beta x
\end{align}

-   **Interpretation**: The regression coefficient $\beta$ in logistic regression represents the **log odds ratio** between $y=0$ and $y=1$.

-   **Estimation**: Maximum likelihood

::: {style="font-size: 80%;"}
## Technical details

-   Many important outcome types can be accommodated by GLMs.

-   Each of these distributions has a location parameter, e.g. $\mu$ for the Gaussian, $p$ for the Bernoulli and Binomial.

-   The natural link function between the location parameter and the linear predictor can be derived from the mathematical form of the distribution.

| Response    | Distribution | E(y)      | Link (g)       |
|-------------|--------------|-----------|----------------|
| Continuous  | Gaussian     | $\mu$     | $1$ (identity) |
| Dichotomous | Bernoulli    | $p$       | $\text{logit}$ |
| Counts      | Poisson      | $\lambda$ | $\log$         |

<https://en.wikipedia.org/wiki/Generalized_linear_model>
:::

## Technical details: GLM

The GLM consists of three elements:

1.  A probability distribution from the exponential family. Note: Only distributions that can be formulated as an exponential family can be modelled as GLM.
2.  A linear predictor $\eta=x\beta$
3.  A link function $g$ such that $E(y) = \mu = g^{-1}(\eta)$

## Technical details: Exponential families

An exponential family is a set of probability distributions of the following form:

$$
f_x(x \mid \theta) = h(x) \exp\{\eta(\theta) \times T(x) - A(\theta)\}
$$

where

-   $\theta$ is the parameter of interest.

-   $T(x)$ is a sufficient statistic.

-   $\eta(\theta)$ is the natural parameter or link function.

::: {style="font-size: 80%;"}
## Gaussian distribution as exponential distribution

Gaussian distribution with unknown $\mu$, but known $\sigma$:

$$
f_{\sigma}(x \mid \mu) =  \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\{ -\frac{(x-\mu)^2}{2\sigma^2} \} =  \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\{ -\frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2} \}
$$

-   $\theta = \mu$

-   $h(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\{ -\frac{x^2}{2\sigma^2} \}$

-   $T(x) = \frac{x}{\sigma}$

-   $\eta(\mu) = \frac{\mu}{\sigma}$

-   $A(\mu) = \frac{\mu^2}{2\sigma^2}$
:::

::: {style="font-size: 80%;"}
## Logistic regression and binary outcomes

Binomial distribution with known number of trials $n$, but unknown probability $p$:

\begin{align} f(x \mid p) &= {n\choose x} p^x (1-p)^{n-x} = \\ &= {n \choose x} \exp \{x \log (\frac{p}{1-p}) + n\log(1-p)\}  \end{align}

-   $\theta = p$

-   $h(x) = {n\choose x}$

-   $T(x)=x$

-   $\eta(p) = \log(\frac{p}{1-p})$

-   $A(p) = - n \log(1-p)$
:::

::: {style="font-size: 80%;"}
## Logistic regression and binary outcomes

Formulate model: Three elements

1.  Error distribution for response variable
2.  Linear predictor
3.  Link function

The three elements of the logistic regression model are:

1.  The Bernoulli probability distribution modelling the data: $P( y_i= 1 \mid x_i ) = p_i$
2.  The linear predictor: $\alpha + \sum_{j=1}^p \beta_j x_{ij}$
3.  The link function $g$ associating the mean of $y$, $P( y_i= 1 \mid x_i )$ to the linear predictor: here the link is the [logistic link]{style="color:red;"} as we set $g(P( y_i= 1 \mid x_i ))=\text{logit}(p_i) = \beta_0 + \sum_{j=1}^p\beta_jx_{ij}$
:::

::: {style="font-size: 70%;"}
## glm() in R

-   GLMs can be called in R just as linear models.

```{r}
#| echo: true
#| eval: true
library(lars)
library(dplyr)

data(diabetes)
x <- as.data.frame.matrix(diabetes$x)
y <- ifelse(diabetes$y > mean(diabetes$y), 1, 0)

glm(y ~ age + sex + bmi + map + ltg, data = x, family = binomial) %>% summary()
```
:::

::: {style="font-size: 85%;"}
## glm() in R

-   Different types of exponential families can be called using the $\text{family}$ option:

    -   $\text{binomial(link = 'logit')}$

    -   $\text{gaussian(link = 'identity')}$

    -   $\text{Gamma(link = 'inverse')}$

    -   $\text{poisson(link='log')}$

-   There are similar return values as for the $\text{lm}$ function:

    -   coefficients

    -   residuals

    -   fitted.values

    -   linear.predictors: the linear fit on the link scale
:::

::: {style="font-size: 80%;"}
## Making predictions

1.  Train the prediction rule
2.  Derive predictions on the linear predictor scale for the new data

```{r}
#| echo: true
#| eval: true
#| warnings: false
#| fig-height: 4
#| message: false


library(lars)
library(dplyr)
library(ggplot2)
library(patchwork)
set.seed(11)

data(diabetes)
x <- as.data.frame.matrix(diabetes$x)
y <- ifelse(diabetes$y > mean(diabetes$y), 1, 0)

glm_predict <- glm(y ~ glu, data = x, family = binomial)
xnew <- data.frame(glu = rnorm(n = 1000, mean = 0, sd = 0.5))
xnew %>% head()

eta <- predict.glm(glm_predict, xnew)
```
:::

## Plot the predictions

```{r}
#| echo: true
#| eval: true
#| warnings: false
#| fig-align: center
ggplot() +
  geom_histogram(aes(x = eta)) |
  ggplot() +
    geom_histogram(aes(x = exp(eta) / (exp(eta) + 1)))
```

```{r}
#| echo: true
#| eval: true
rbinom(
  n = length(eta),
  size = rep(1, length(eta)),
  prob = exp(eta) / (exp(eta) + 1)
) %>% head()
```

## Take away: Generalised linear model

The model formulation in GLMs consists of three elements:

1.  Error distribution for response variable
2.  Linear predictor
3.  Link function

Most common data types can be modelled using GLMs

-   Continuous $\rightarrow$ Gaussian distribution

-   Dichotomous or binary $\rightarrow$ Bernoulli distribution

-   Counts $\rightarrow$ Poisson or Binomial (with known number of trial) distribution

## Questions?
