---
title: "Advanced Regression: Introduction to non-linear regression"
date: "02-27-2024"
author:
  name: "Garyfallos Konstantinoudis"
institute: "Imperial College London"
editor: visual
date-format: medium
title-slide-attributes:
  data-background-color: "#f3f4f4"
  data-background-image: "../../assets/logo_trans.png"
  data-background-size: 50%
  data-background-position: 90% 120%
format:
    revealjs:
      theme: [default, ../../assets/style.scss]
      logo: "../../assets/logo_trans.png"
      slide-number: true
      incremental: false
      chalkboard:
        buttons: false
---

::: {style="font-size: 90%;"}
## Non-linear regression

So far we have studied the linear regression models, which are very flexible tool for estimating relationships in a set of data. In particular, we have seen:

-   Model set up, fitting, and residual diagnostics.

-   Model building and model comparison.

-   ANOVA/ likelihood ratio test.

-   Random intercepts and random slopes.

::: {.callout-note icon="false"}
One of the most crucial assumptions of the previous lecture was that the associations between the outcome and the covariates are linear. What if the association was not linear?
:::
:::

::: {style="font-size: 90%;"}
## A clarification

In the name normal (or Poisson, binomial, etc.) linear model, the word 'linear' refers to the response being modelled as a linear combination of covariates, i.e.

$$Y_i \sim N(\beta_1 + \beta_2X_{i2} + \dots + \beta_pX_{ip}, \sigma^2)$$

It does not refer to each covariate-response relationship being linear. Therefore the following is also within the class of normal linear models

$$Y_i \sim N(\beta_1 + \beta_2X_{i} + \beta_3X_{i}^2, \sigma^2)$$

Here, the relationship between Y and x is quadratic, but it is still a linear model.
:::

## So how do you tell if the relationship is linear?

-   Plot each covariate against the response and see what shape the relationship is.

-   Make sure you plot it with the transformation used in the model.

-   If linear, fit a linear model, if not start thinking of the shape of the relationship.

-   Fit as simple a model as possible, do not overcomplicate it unnecessarily. (Occam's razor)

::: {style="font-size: 80%;"}
## Example

Associations are not solely linear

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| message: false
#| warning: false

library(dplyr)
library(ggplot2)

set.seed(11)
x <- rnorm(n = 1000)
y <- 0.5 * x * x + rnorm(1000, sd = 0.3)

ggplot(data = data.frame(x = x, y = y), aes(x = x, y = y)) +
  geom_point(cex = 1.2) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, linewidth = 1) +
  theme(text = element_text(size = 15))
```
:::

## Basis Expansions

We need to define a set of flexible functions that could capture relationships that are not linear. In general, we can write:

$$Y _i = \sum_j^K\beta_j \phi_j(X_j) + \epsilon_i$$

which we can write: $f(X) = \beta^T\Phi(X)$ and we say that $\Phi(X)$ is a basis system for $f$.

## The polynomial basis function

$$\Phi(X) = (1) \text{ ,thus } Y _i = \beta_0 + \epsilon_i$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-height: 4
#| message: false
#| warning: false

library(dlnm)
library(patchwork)
library(orthopolynom)

data(chicagoNMMAPS)
leg4coef <- legendre.polynomials(n = 5)

ggplot() +
  geom_hline(yintercept = leg4coef[[1]], linewidth = 1) +
  xlim(-1, 1) +
  ylim(-1, 2) +
  theme_bw() +
  ylab("") +
  xlab("") -> p1
chicagoNMMAPS %>%
  filter(year == 1987) %>%
  ggplot(aes(x = time, y = temp)) +
  geom_point(cex = 1.3) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ 1, se = FALSE, cex = .6, linewidth = 1) -> p2

p1 | p2 + theme(text = element_text(size = 15))
```

## The polynomial basis function

$$\Phi(X) = (1 X) \text{ ,thus } Y _i = \beta_0 + \beta_1 X_1 + \epsilon_i$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-height: 4
#| message: false
#| warning: false

library(RColorBrewer)
cols <- RColorBrewer::brewer.pal(n = 8, "Set1")

data(chicagoNMMAPS)

ggplot() +
  geom_abline(slope = 1, intercept = 0, col = cols[1], cex = .6, linewidth = 1) +
  geom_hline(yintercept = leg4coef[[1]], linewidth = 1) +
  xlim(-1, 1) +
  ylim(-1, 2) +
  theme_bw() +
  ylab("") +
  xlab("") -> p1

chicagoNMMAPS %>%
  filter(year == 1987) %>%
  ggplot(aes(x = time, y = temp)) +
  geom_point(cex = 1.3) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, cex = .6, linewidth = 1) -> p2

p1 | p2
```

## The polynomial basis function

$$\Phi(X) = (1 \; X \; X^2) \text{ ,thus } Y _i = \beta_0 + \beta_1 X + \beta_2 X^2 + \epsilon_i$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-height: 4

ggplot() +
  geom_abline(slope = 1, intercept = 0, col = cols[1], cex = .6, linewidth = 1) +
  geom_hline(yintercept = leg4coef[[1]], cex = .6, linewidth = 1) +
  xlim(-1, 1) +
  ylim(-1, 2) +
  geom_line(aes(
    x = seq(from = -1, to = 1, length.out = 1000),
    y = -0.5 + 1.5 * seq(from = -1, to = 1, length.out = 1000)^2
  ), linewidth = 1, col = cols[2]) +
  theme_bw() +
  ylab("") +
  xlab("") -> p1

chicagoNMMAPS %>%
  filter(year == 1987) %>%
  ggplot(aes(x = time, y = temp)) +
  geom_point(cex = 1.3) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, cex = .6, linewidth = 1) -> p2

p1 | p2
```

## The polynomial basis function

$$\Phi(X) = (1 \; X \; X^2 \; X^3) \text{ ,thus } Y _i = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \epsilon_i$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-height: 4
x.plot <- seq(from = -1, to = 1, length.out = 1000)
y <- -1.5 * x.plot + 2.5 * x.plot^3

ggplot() +
  geom_abline(slope = 1, intercept = 0, col = cols[1], cex = .6, linewidth = 1) +
  geom_hline(yintercept = leg4coef[[1]], cex = .6, linewidth = 1) +
  xlim(-1, 1) +
  ylim(-1, 2) +
  geom_line(aes(
    x = seq(from = -1, to = 1, length.out = 1000),
    y = -0.5 + 1.5 * seq(from = -1, to = 1, length.out = 1000)^2
  ), col = cols[2], cex = .6, linewidth = 1) +
  geom_line(aes(
    x = x.plot,
    y = y
  ), col = cols[3], cex = .6, linewidth = 1) +
  theme_bw() +
  ylab("") +
  xlab("") -> p1

chicagoNMMAPS %>%
  filter(year == 1987) %>%
  ggplot(aes(x = time, y = temp)) +
  geom_point(cex = 1.3) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3), se = FALSE, cex = .6, linewidth = 1) -> p2

p1 | p2
```

## The polynomial basis function

$$\Phi(X) = (1 \; X \; X^2 \; X^3 \; X^4) \text{ ,thus}$$

$$Y _i = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \beta_4 X^4 + \epsilon_i$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-height: 4

x.plot.1 <- seq(from = -1, to = 1, length.out = 1000)
y.1 <- 0.375 - 3.75 * x.plot.1^2 + 4.375 * x.plot.1^4

ggplot() +
  geom_abline(slope = 1, intercept = 0, col = cols[1], cex = .6, linewidth = 1) +
  geom_hline(yintercept = leg4coef[[1]], cex = .6, linewidth = 1) +
  xlim(-1, 1) +
  ylim(-1, 2) +
  geom_line(aes(
    x = seq(from = -1, to = 1, length.out = 1000),
    y = -0.5 + 1.5 * seq(from = -1, to = 1, length.out = 1000)^2
  ), col = cols[2], cex = .6, linewidth = 1) +
  geom_line(aes(
    x = x.plot,
    y = y
  ), col = cols[3], cex = .6, linewidth = 1) +
  geom_line(aes(
    x = x.plot.1,
    y = y.1
  ), col = cols[4], cex = .6, linewidth = 1) +
  theme_bw() +
  ylab("") +
  xlab("") -> p1

chicagoNMMAPS %>%
  filter(year == 1987) %>%
  ggplot(aes(x = time, y = temp)) +
  geom_point(cex = 1.3) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3) + I(x^4), se = FALSE, cex = .6, linewidth = 1) -> p2

p1 | p2
```

## The polynomial basis function

$$\Phi(X) = (1 \; X \; X^2 \; X^3 \; X^4 \; X^5) \text{ ,thus }$$

$$Y _i = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \beta_4 X^4 +\beta_5 X^5 + \epsilon_i $$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-height: 4

x.plot.2 <- seq(from = -1, to = 1, length.out = 1000)
y.2 <- 1.875 * x.plot.2 - 8.75 * x.plot.2^3 + 7.875 * x.plot.2^5

ggplot() +
  geom_abline(slope = 1, intercept = 0, col = cols[1], cex = .6, linewidth = 1) +
  geom_hline(yintercept = leg4coef[[1]], cex = .6, linewidth = 1) +
  xlim(-1, 1) +
  ylim(-1, 2) +
  geom_line(aes(
    x = seq(from = -1, to = 1, length.out = 1000),
    y = -0.5 + 1.5 * seq(from = -1, to = 1, length.out = 1000)^2
  ), col = cols[2], cex = .6, linewidth = 1) +
  geom_line(aes(
    x = x.plot,
    y = y
  ), col = cols[3], cex = .6, linewidth = 1) +
  geom_line(aes(
    x = x.plot.1,
    y = y.1
  ), col = cols[4], cex = .6, linewidth = 1) +
  geom_line(aes(
    x = x.plot.2,
    y = y.2
  ), col = cols[5], cex = .6, linewidth = 1) +
  theme_bw() +
  ylab("") +
  xlab("") -> p1

chicagoNMMAPS %>%
  filter(year == 1987) %>%
  ggplot(aes(x = time, y = temp)) +
  geom_point(cex = 1.3) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5), se = FALSE, cex = .6, linewidth = 1) -> p2

p1 | p2
```

::: {style="font-size: 80%;"}
## Example

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
set.seed(11)
x <- rnorm(n = 1000)
y <- 0.5 * x * x + rnorm(1000, sd = 0.3)

lm(y ~ x) %>% summary()
```

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 10
library(ggplot2)

set.seed(11)
x <- rnorm(n = 1000)
y <- 0.5 * x * x + rnorm(1000, sd = 0.3)

ggplot(data = data.frame(x = x, y = y), aes(x = x, y = y)) +
  geom_point(cex = 3) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, linewidth = 2) +
  theme(text = element_text(size = 15))
```
:::

## Fit a polynomial in R

```{r}
#| echo: true
#| eval: true
lm(y ~ x + I(x^2) + I(x^3)) %>% summary()
```

## How can we test the linearity assumption

-   Notice that the linear model is nested in the quadratic form

-   The same holds for cubic vs quadratic vs linear

```{r}
#| echo: true
#| eval: true

mod1 <- lm(y ~ x + I(x^2))
mod2 <- lm(y ~ x + I(x^2) + I(x^3))
anova(mod1, mod2)
```

::: {style="font-size: 80%;"}
## Pros and cons

Pros

-   These curves are quite flexible---a quadratic can fit most biologically plausible curves

-   The curves only use 1(quadratic) or 2(cubic) degrees of freedom more than linear, unlike dummy variable models

-   The results are not sensitive to choice of boundaries (there aren't any)

-   Outliers mostly influence the extremes of the curve, not the center part

Cons

-   They use more degrees of freedom than linear, and therefore have less power

-   There is still some sensitivity to influential observations
:::

## Other types of basis function

-   **Harmonics** - The Fourier basis function

    $$1, sin(\omega X), cos(\omega X), sin(2\omega X), cos(2\omega X), \dots, $$

    $$sin(m \omega X), cos(m \omega X)$$

-   constant $\omega$ defines the period of oscillation of the first sine/cosine pair. This is $\omega = 2\pi/P$ where $P$ is the period.

## Example: Fourier basis function

$$\Phi(X) = (1 \; sin(\omega X) \; cos(\omega X) \; sin(2\omega X) \; cos(2\omega X)) \text{ ,thus }$$

$$Y _i = \beta_0 + \beta_1 sin(\omega X) + \beta_2 cos(\omega X) + \beta_3 sin(2 \omega X) + \beta_4 cos(2\omega X) + \epsilon_i$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 10

P <- 360
omega <- 2 * pi / P
x <- seq(from = 0, to = 360, length.out = 1000)
y <- sin(2 * omega * x)

ggplot() +
  geom_line(aes(x = x, y = sin(2 * omega * x)), cex = .6, col = cols[1]) +
  geom_line(aes(x = x, y = cos(2 * omega * x)), cex = .6, col = cols[2]) +
  theme_bw() +
  xlab("") +
  ylab("") -> p1

chicagoNMMAPS %>%
  filter(year == 1987) %>%
  ggplot(aes(x = time, y = temp)) +
  geom_point(cex = .8) +
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ I(sin(omega * x)) + I(cos(omega * x)) + I(sin(2 * omega * x)) + I(2 * cos(omega * x)), se = FALSE, cex = .6) -> p2

p1 | p2
```

::: {style="font-size: 90%;"}
## Pros and cons

Pros

-   Excellent computational properties, especially if the observations are equally spaced.

-   Natural for describing periodic data, such as the annual weather cycle

-   The results are not sensitive to choice of boundaries (there aren't any)

Cons

-   functions are periodic; this can be a problem if the data are, for example, growth curves.
:::

## Parametric non-linear effects

-   The following models captured the non-linear relationships using simple non-linear functions.

-   These types of models are to be preferred if possible, because again they are simpler to make inference from, e.g. the relationship is quadratic.

-   However, there may be times when the relationship being modelled does not look like a parametric function. Then what should you do?

## Parametric non-linear effects

Consider the following form

```{r}
set.seed(11)
x <- rnorm(n = 1000)
y <- numeric(1000)
y[x < 0] <- 1 + 0.5 * x[x < 0] + 0.2 * x[x < 0]^2 + rnorm(n = length(x[x < 0]), sd = 0.2)
y[x >= 0] <- 0.5 + sin(2 * pi / 2 * x[x >= 0]) + rnorm(n = length(x[x > 0]), sd = 0.3)

ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  theme(text = element_text(size = 15))
```

It doesn't look like any simple parametric form (e.g. polynomial, sinusoidal, etc), so what do you do?

## Smooth functions

-   There are many methods to estimate non-linear relationships such as that on the previous slide.

-   They are generically called smooth functions, and include splines (lots of different types), kernel smoothers and local linear smoothers.

-   We will focus on splines in this lab, because they are simple to understand graphically and are easy to fit to the data.

## Splines

-   Splines were originally thin splints of wood used to trace complex, smooth curves in engineering and architectural.

-   Splines were pinned to the drawing at points where the spline changed its curvature.

![](Figures/splinesExample.png){fig-align="center"}

## Piecewise Linear Splines

-   We begin fitting splines by dividing the range of exposure into pieces.
-   Instead of fitting a constant in each piece, we fit a separate linear term in each piece.
-   This has more power since it allows variation within categories to predict variation in outcome.
-   We can use fewer categories to capture the deviation from a strictly linear curve because we have slopes within category.

## Linear threshold in R

```{r}
#| echo: true
#| eval: true

dat <- data.frame(x = x, y = y)

lm(y ~ x:(x <= -1) + x:(x <= 0.5) + x:(x <= 1.5) + x:(x <= 3), data = dat) -> mod1
mod1 %>% summary()
```

## Linear threshold in R

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 10

dat %>%
  mutate(
    mean = mod1$fitted.values,
    disc = case_when(
      dat$x <= -1 ~ 1,
      dat$x > -1 & dat$x <= 0.5 ~ 2,
      dat$x > 0.5 & dat$x <= 1.5 ~ 3,
      dat$x > 1.5 & dat$x <= 3 ~ 4,
      dat$x > 3 ~ 5
    )
  ) %>%
  ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  geom_line(aes(x = x, y = mean, group = disc), lwd = 1.2) +
  theme_bw() +
  theme(text = element_text(size = 15))
```

## Linear splines in R

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 10
#| message: false
#| warning: false

library(splines)
fit <- lm(y ~ bs(x, degree = 1, knots = c(-1, 0.5, 1.5, 3)), data = dat)

ggplot() +
  geom_point(aes(x = x, y = y), col = cols[1], cex = 1) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = fit$fitted.values), lwd = 1) +
  theme(text = element_text(size = 15))
```

::: {style="font-size: 80%;"}
## Linear splines

Linear threshold model

```{=tex}
\begin{align}
Y_i &= \beta_0^{(1)} + \beta_1^{(1)}x + \epsilon_i \qquad x\leq-1\\
Y_i &= \beta_0^{(2)} + \beta_1^{(2)}x + \epsilon_i \qquad -1<x\leq0.5\\
Y_i &= \beta_0^{(3)} + \beta_1^{(3)}x + \epsilon_i \qquad 0.5<x\leq1.5\\
Y_i &= \beta_0^{(4)} + \beta_1^{(4)}x + \epsilon_i \qquad 1.5<x\leq3\\
Y_i &= \beta_0^{(5)} + \beta_1^{(5)}x + \epsilon_i \qquad x\geq3\\
\end{align}
```
Linear spline model

$Y_i = \beta_0 + \beta_1x + \beta_2(x+1)_+ + \beta_3(x-0.5)_+ + \beta_4 (x-1.5)_+ + \beta_5(x-3)_+ + \epsilon_i$

$$(x-k)_+=\begin{cases} 0, \quad x<k \\ x-k, \quad x\geq k\\\end{cases}$$
:::

## Linear splines in R without a package

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 10

lm(y ~ x + I((x + 1) * (x >= -1)) + I((x - 0.5) * (x >= 0.5)) + I((x - 1.5) * (x >= 1.5)) + I((x - 3) * (x >= 3)), data = dat) -> mod2

ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = mod2$fitted.values), lwd = 1) +
  theme(text = element_text(size = 15))
```

::: {style="font-size: 80%;"}
## Cubic splines

Similarly we can define higher order polynomial splines, for instance:

```{=tex}
\begin{align}
Y_i = \beta_0 &+ \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \\
& \beta_4 (X+1)_+ + \beta_5 (X+1)_+^2 + \beta_6(X+1)_+^3 + \\
& \beta_7 (x-0.5)_+ + \beta_8 (x-0.5)_+^2 + \beta_9 (x-0.5)_+^3 + \\
&\dots + \epsilon_i \\
(x-k)_+ & = 
\begin{cases}
0, \quad x<k \\ x-k, \quad x\geq k
\end{cases}
\end{align}
```
which reduces to the following to ensure smooth curvature on the knots (it can be seen after deriving the first and second derivative):

```{=tex}
\begin{align}
Y_i = \beta_0 & + \beta_1 x +\beta_2 x^2 + \beta_3 x_3 + \\
&\beta_6 (x+1)_+^3 + \beta_9(x-0.5)_+^3 + \dots + \epsilon_i 
\end{align}
```
:::

::: {style="font-size: 80%;"}
## Cubic splines in R

```{r}
#| echo: true
#| eval: true
fit_c <- lm(y ~ bs(x, degree = 3, knots = c(-1, 0.5, 1.5, 3)), data = dat)
```

without the splines package:

```{r}
#| echo: true
#| eval: true
fit_nopack <- lm(
  y ~ x + I(x^2) + I(x^3) + I((x + 1)^3 * (x >= -1)) +
    I((x - 0.5)^3 * (x >= 0.5)) + I((x - 1.5)^3 * (x >= 1.5)) + I((x - 3)^3 * (x >= 3)),
  data = dat
)
```

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 10
ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = fit_nopack$fitted.values), lwd = 1) +
  theme(text = element_text(size = 15))
```
:::

::: {style="font-size: 80%;"}
## Splines

A spline of order n is a piecewise polynomial function of degree $n-1$ in a variable $x$.

(Basis) Splines can be:

-   Piecewise constant.

-   Linear.

-   Quadratic.

-   Cubic.

-   higher order polynomials.

-   etc.

Why are the borders so wiggly?
:::

## Natural cubic splines

-   Splines can have high variance in the boundaries.

-   This problem aggravates if knots too few.

-   The natural spline constraints the fit to be linear before and after the first and last knots.

-   This stabilises the fitting and makes a more reasonable assumption.

::: {style="font-size: 90%;"}
## Natural cubic splines in R

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 10

fit_ns <- lm(y ~ ns(x, knots = c(-1, 0.5, 1.5, 3)), data = dat)

ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = fit_ns$fitted.values), lwd = 1) +
  theme(text = element_text(size = 15))
```
:::

::: {style="font-size: 90%;"}
## Well, better fit be achieved with more knots

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 10
fit_ns2 <- lm(y ~ ns(x, df = 10), data = dat)

ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = fit_ns2$fitted.values), lwd = 1)
```
:::

::: {style="font-size: 90%;"}
## ... and more

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 10
fit_ns2 <- lm(y ~ ns(x, df = 50), data = dat)

ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = fit_ns2$fitted.values), lwd = 1)
```
:::

::: {style="font-size: 90%;"}
## ... and more

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 10
fit_ns3 <- lm(y ~ ns(x, df = 100), data = dat)

ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = fit_ns3$fitted.values), lwd = 1)
```
:::

::: {style="font-size: 90%;"}
## ... and more

```{r}
#| echo: true
#| eval: true
#| fig-align: "center"
#| fig-width: 10
fit_ns4 <- lm(y ~ ns(x, df = 1000), data = dat)

ggplot() +
  geom_point(aes(x = x, y = y), cex = 1.3, col = cols[1]) +
  theme_bw() +
  xlab("") +
  ylab("") +
  geom_line(aes(x = dat$x, y = fit_ns4$fitted.values), lwd = 1)
```

is this a useful model?
:::

## Summary

-   Introduction to different basis function and how to fit them in R

-   Theory and application of linear splines

-   Understand more flexible non-parametric functions (focus on splines)

Questions?
