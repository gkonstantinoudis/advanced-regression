---
title: "Practical 5: The epigenetic clock: Predicting biological age on new data"
author: "Garyfallos Konstantinoudis"
date: "Spring Term 2025"
output:
  pdf_document: default
highlight: tango
---



## Part 1: The epigenetic clock: Non-parametric prediction using random forests


In this practical we consider again the same data on $n=409$ healthy mice and methylation of $p=3,663$ conserved methylation sites as in the last two weeks. This time we are interested in random forests and see if random forests will provide a better prediction rule than penalised regression techniques. Install and load the package


```{r message=FALSE, warning=FALSE, fig.height=3.2}
library("randomForest")
library("dplyr")
```

Load the dataset, that contains the methylation matrix as predictor matrix and the age of the mice (in months) stored in the vector y. Familiarise yourself with the dataset using the following commands

```{r message=FALSE, warning=FALSE, fig.height=3.2}
load("../../data/data_epigenetic_clock_control")
# alternatively try load("../../data/data_epigenetic_clock_control.dms")
y <- control_mice$y_control
x <- control_mice$x_control
dim(x)
```


Question 1.1

First compute a random forest with the options 'ntree=100' and 'importance = TRUE' and save the output to an object call rf.out or similar.


*Reply: It is very easy to build a random forest: all we need to specify is x and y. Set 'ntree=100' for now and importance =TRUE allows us to assess which variables are important. See next question.*

```{r message=FALSE, warning=FALSE}
rf.out <- randomForest(x = x, y = y, ntree = 100, importance = TRUE)
```



Question 1.2

Random forests have an intrinsic way of assigning variable importance to the predictors. How do random forests with quantitative outcome rank variables according to their importance? Rank the variables according to their importance and display the 10 most important methylation sites for ageing in the random forest algorithm. Use the varImpPlot() function to visualise the variable importance.

*Reply: Random forests offer two different measures for importance that are returned when setting importance = TRUE:
-Permutation: Mean decrease in accuracy (%IncMSE)
First the random forest is generated and the prediction accuracy (mse) is evaluated on the out-of-bag samples. Then for a particular variable j the values of the out-of-bag samples are permuted and the prediction accuracy is evaluated on the permuted out-of-bag samples. The mean decrease of mse after permuting variable j is used to indicate the importance of a variable.
-Gini-index: Mean decrease in impurity (IncNodePurity)
Alternatively, the mean decrease of impurity can be used to measure variable importance. For quantitative traits, impurity can be measured using residual sum of squares. It is computed as the decrease of impurity every time a tree is split at variable j and averaged over all trees.
 *

```{r message=FALSE, warning=FALSE, fig.height=5}
importance <- rf.out$importance
importance[order(importance[, 2], decreasing = TRUE), ][1:10, ]
varImpPlot(rf.out)
```

Question 1.3

How would you run bagging using the randomForest function? What is the interpretation of the mtry option?

*Reply: mtry indicates how many predictors of x should be considered to split the tree. Setting mtry to the number of columns of the predictor matrix is basically a bagging approach and not a random forest. *

```{r message=FALSE, warning=FALSE}
bagging.out <- randomForest(x = x, y = y, ntree = 100, importance = TRUE, mtry = ncol(x))
```


Question 1.4


Next step is to write a prediction function for the random forest algorithm. Re-use your code from last week (Practical 3 Question 2) and see the prediction function for a linear regression model below. Set the number of trees as an open parameter.

```{r message=FALSE, warning=FALSE}
predfun.lm <- function(train.x, train.y, test.x, test.y) {
  # fit the model and build a prediction rule
  lm.fit <- lm(train.y ~ ., data = train.x)
  # predict the new observation based on the test data and the prediction rule
  ynew <- predict(lm.fit, test.x)
  # compute mse as squared difference between predicted and observed outcome
  out <- mean((ynew - test.y)^2)
  return(out)
}
```

*Reply: The following code can be used as a prediction function. Adding ntree as open parameter allows us to compare the performance for different training length of the random forest algorithm. *

```{r message=FALSE, warning=FALSE}
predfun.rf <- function(train.x, train.y, test.x, test.y, ntree) {
  # fit the model and build a prediction rule
  rf.fit <- randomForest(x = train.x, y = train.y, ntree = ntree)
  # predict the new observation based on the test data and the prediction rule
  ynew <- predict(rf.fit, newdata = test.x)
  # compute squared error risk (MSE)
  out <- mean((ynew - test.y)^2)
  return(out)
}
```



Question 1.5

Compare the prediction performance  using ntree = 10 and ntree = 100 random trees to train the random forest. To this end use the
```{r message=FALSE, warning=FALSE}
library(crossval)
```
package and compare the two parameters using $k$-fold cross-validation (cv) using $k=5$ folds and B=10 repetitions (Ideally you would want to run this with more repetitions (B=100 to B=1000), but for this practical 10 will do).

*Reply: We find that the random forest that was trained using more random trees performs better. It is recommended to use at least 500 or more trees. *
```{r message=FALSE, warning=FALSE}
set.seed(14)
cv.out.rf10 <- crossval(predfun.rf, x, y, ntree = 10, K = 5, B = 10, verbose = FALSE)
cv.out.rf10$stat
cv.out.rf10$stat.se
cv.out.rf100 <- crossval(predfun.rf, x, y, ntree = 100, K = 5, B = 10, verbose = FALSE)
cv.out.rf100$stat
cv.out.rf100$stat.se
```





Question 1.6

Finally, we want to know if random forests outperform regularised regression with respect to prediction performance. Re-use the following code from last week (Practical 3 Question 2) as prediction rule for glmnet()

```{r message=FALSE, warning=FALSE}
library(glmnet)
predfun.glmnet <- function(train.x, train.y, test.x, test.y, lambda = lambda, alpha = alpha) {
  # fit glmnet prediction rule
  glmnet.fit <- glmnet(x = train.x, y = train.y, lambda = lambda, alpha = alpha)
  # predict the new observation based on the test data and the prediction rule
  ynew <- predict(glmnet.fit, newx = test.x)
  # compute squared error risk (MSE)
  out <- mean((ynew - test.y)^2)
  return(out)
}
```
and perform cv to tune the regularisation parameter.

```{r message=FALSE, warning=FALSE}
library(foreach)
set.seed(12)
lasso.cv <- cv.glmnet(x, y, family = "gaussian", alpha = 1, type.measure = "mse")
set.seed(123)
ridge.cv <- cv.glmnet(x, y, family = "gaussian", alpha = 0, type.measure = "mse")
set.seed(1234)
a <- seq(0.05, 0.95, 0.05)
search <- foreach(i = a, .combine = rbind) %do% {
  cv <- cv.glmnet(x, y, family = "gaussian", type.measure = "mse", alpha = i)
  data.frame(
    cvm = cv$cvm[cv$lambda == cv$lambda.1se],
    lambda.1se = cv$lambda.1se, alpha = i
  )
}
elasticnet.cv <- search[search$cvm == min(search$cvm), ]
```

Finally, use cv as implemented in crossval() to determine if random forests (ntree = 100) is better than lasso and elastic net as implemented in the glmnet package.



*Reply: We use the crossval function to compare different methods. We find that elastic net has the lowest cross-validation error, followed by lasso. This is a surprising results because random forests are generally known to outperform other methods. See for example the Article 'Do we Need Hundreds of Classifiers to Solve Real World Classification Problems? here:*

http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf


```{r message=FALSE, warning=FALSE}
set.seed(15)
cv.out.ridge <- crossval(predfun.glmnet, x, y,
  lambda = ridge.cv$lambda.1se,
  alpha = 0, K = 5, B = 10, verbose = FALSE
)
cv.out.lasso <- crossval(predfun.glmnet, x, y,
  lambda = lasso.cv$lambda.1se,
  alpha = 1, K = 5, B = 10, verbose = FALSE
)
cv.out.enet <- crossval(predfun.glmnet, x, y,
  lambda = elasticnet.cv$lambda.1se,
  alpha = elasticnet.cv$alpha, K = 5, B = 10, verbose = FALSE
)
table.out <- rbind(
  c(cv.out.ridge$stat, cv.out.ridge$stat.se), c(cv.out.lasso$stat, cv.out.lasso$stat.se),
  c(cv.out.enet$stat, cv.out.enet$stat.se), c(cv.out.rf10$stat, cv.out.rf10$stat.se), c(cv.out.rf100$stat, cv.out.rf100$stat.se)
)
rownames(table.out) <- c("ridge", "lasso", "elastic net", "rf 10", "rf 100")
colnames(table.out) <- c("mse", "se")
table.out
```




## Part 2: The epigenetic clock: Evaluating the impact of nitrogen dioxide on biological age


An environmental research group gets in contact with us. They have measured the methylation profile of $n=131$ mice of which $36$ mice have been exposed to nitrogen dioxide (NO2) for 10 hours a day for 10 weeks. The remaining $95$ mice are healthy controls. Load the data and familiarise yourself with the data structure.

```{r message=FALSE, warning=FALSE, fig.height=3.2}
load("../../data/data_epigenetic_clock_experimental")
# alternatively try load("../../data_epigenetic_clock_experimental.dms")
exposed <- experimental_mice$exposed
table(exposed)
x.test <- experimental_mice$x_exp
dim(x.test)
```
The working hypothesis is that NO2 exposure reduces the biological age of mice and makes the exposed mice age more quickly. The environmental research group asks us to predict the biological age of the mice using our algorithms to determine the biological age of a mouse.


Question 2.1

Predict the biological age of the $n=140$ new mice using the lasso model as implemented in the glmnet package. Use again $\$$lambda.1se as the regularisation parameter (as computed in Question 1.6) and save the predicted age in an object called lasso.hat.


*Reply: For completeness we repeat here the analysis from last week and save the lasso predictions of the new data (x.test) to the object lasso.hat.*

```{r message=FALSE, warning=FALSE}
# building the prediction rule
lasso.cv.out <- glmnet(x, y, family = "gaussian", alpha = 1, lambda = lasso.cv$lambda.1se)
# evaluating on the new data
lasso.hat <- predict(lasso.cv.out, newx = x.test, s = lasso.cv$lambda.1se)
```




Question 2.2

Predict the biological age of the $n=131$ new mice using the ridge model. Use again $\$$lambda.1se as the regularisation parameter (as computed in Question 1.6) and save the predicted age in an object called ridge.hat.


*Reply: In analogy, we perform first cv, then build the ridge prediction rule and finally make the predictions of the new data (x.test) and save them in the object ridge.hat.*

```{r message=FALSE, warning=FALSE}
# building the prediction rule
ridge.cv.out <- glmnet(x, y, family = "gaussian", alpha = 0, lambda = ridge.cv$lambda.1se)
# evaluating on the new data
ridge.hat <- predict(ridge.cv.out, newx = x.test, s = ridge.cv$lambda.1se)
```




Question 2.3

Predict the biological age of the $n=131$ new mice using the elastic net model. Use again $\$$lambda.1se as the regularisation parameter (as computed in Question 1.6) and save the predicted age in an object called enet.hat.


*Reply: And we repeat this for the elastic net as well and save the predictions in the elasticnet.hat object.*

```{r message=FALSE, warning=FALSE}
# building the prediction rule
enet.out <- glmnet(x, y,
  family = "gaussian",
  lambda = elasticnet.cv$lambda.1se, alpha = elasticnet.cv$alpha
)
# evaluating on the new data
enet.hat <- predict(enet.out,
  newx = x.test,
  lambda = elasticnet.cv$lambda.1se, alpha = elasticnet.cv$alpha
)
```


Question 2.4

Predict the biological age of the $n=131$ new mice using the a random forest model. This time use "ntree=500" to build a reliable prediction rule and save the predicted age in an object called rf.hat.

*Reply: Similarly we can use the random forest model from Question 1.1 for prediction and save the predictions in the rf.hat object.*

```{r message=FALSE, warning=FALSE}
# building the prediction rule
rf.out <- randomForest(x = x, y = y, importance = TRUE, ntree = 500)
# evaluating on the new data
rf.hat <- predict(rf.out, newdata = x.test)
```

Question 2.5

Can you confirm the working hypothesis that NO2 exposure reduces the biological age of mice? Perform a $t$-test to see if the predicted biological age of the mice differs significantly between exposed and healthy mice. Perform a $t-$test for all four predictions done in Question 2.1-2.4. How will you advice the environmental research group?

*Reply: We perform a $2$ group $t$-test for each epigenetic clock where we test if the biological (predicted) age differs between exposed and healthy control mice.*

```{r message=FALSE, warning=FALSE}
# random forest
t.test(rf.hat ~ as.factor(exposed))
# ridge
t.test(ridge.hat ~ as.factor(exposed))
# lasso
t.test(lasso.hat ~ as.factor(exposed))
# elastic net
t.test(enet.hat ~ as.factor(exposed))
```

*Interpretation: We do see a significant difference in biological age using the lasso and elastic net prediction rules. Given the cross-validation we performed in Section 1.5 we know that both lasso and elastic net have the best prediction performance. Since both lasso and  elastic net agree that the mice who have been exposed to NO2 did age quicker than the mice in the control group we are confident that NO2 exposure impacts the epigenetic clock of mice.
*




## Part 3: Decision trees and random forests: Survival on the Titanic


The sinking of the titanic was one of the greatest disaster in navel history. After colliding with an iceberg, the titanic sank and 1,502 out of 2,224 passengers and crew were killed. The following data set has collected information on n=1,309 of the passengers and their survival.

```{r message=FALSE, warning=FALSE}
titanic <- read.csv("../../data/titanic.csv")
dim(titanic)
table(titanic$survived)
```

Here we use decision trees and random forest to analyse the titanic data. Make sure to have the following two packages
```{r message=FALSE, warning=FALSE}
library(tree)
library(randomForest)
```
installed.


Question 3.1

Fit a decision tree on the titanic data using the following predictor matrix including passenger class, sex, age, number of siblings/spouses aboard, and number of parents/children aboard after excluding missing values.

```{r message=FALSE, warning=FALSE}
x <- cbind(titanic$pclass, titanic$sex, titanic$age, titanic$sibsp, titanic$parch)
rm <- which(is.na(titanic$age) == TRUE)
# alternatively use rm = which(!is.na(titanic$age)==TRUE) or rm = which(is.na(titanic$age)==FALSE)
x.input <- x[-rm, ]
dim(x.input)
colnames(x.input) <- c("pclass", "sex", "age", "sibsp", "parch")
y.input <- as.factor(titanic$survived[-rm])
table(y.input)
```
Use the function tree in the tree package.
```{r message=FALSE, warning=FALSE, fig.height =4.5}
tree.out <- tree(y.input ~ x.input)
plot(tree.out)
text(tree.out)
```

Question 3.2

What is a concern when fitting a single decision tree?

*Reply: Decision trees are prone to over-fitting. This can be prevented by either cross-validation or performing a random forest approach.*

Question 3.3

Prune your tree using cross-validation (cv.tree) and use the option FUN = prune.misclass for the misclassification rate as criterion. Choose the model with the lowest misclassification error and plot the tree. How do you interpret the decision tree?

```{r message=FALSE, warning=FALSE}
set.seed(33)
cv.out <- cv.tree(tree.out, FUN = prune.misclass)
cv.out
```
*Reply: The models with size 6 and 5 have the same missclassification error ($dev=211). We decide to use the smaller model of size 5.*

```{r message=FALSE, warning=FALSE, fig.height =4.5}
pruned.tree <- prune.tree(tree.out, best = 5)
plot(pruned.tree)
text(pruned.tree)
```

*Interpretation: The first split is for female on the left and male on the right. For female the next split is passenger class, where class 1 and 2 are predicted to survive. For male the next split is on age, where men older than 9.5 years do not survive and men younger than 9.5 have another split at the variable siblings. Boys with fewer than 3 siblings survived, while boys with more siblings do not survive.*


Question 3.4

Finally fit a random forest to the data and look at the variable importance. What was the key variable for survival in the titanic disaster?

```{r message=FALSE, warning=FALSE, fig.height =4}
x.input <- as.data.frame(x.input)
summary(x.input)
x.input$pclass <- as.numeric(x.input$pclass)
x.input$age <- as.numeric(x.input$age)
x.input$sibsp <- as.numeric(x.input$sibsp)
x.input$parch <- as.numeric(x.input$parch)

rf.out <- randomForest(y = y.input, x = x.input)
varImpPlot(rf.out, main = "")
```

*Reply: The most important variables are sex and age, reinforcing the 'women and children first' hypothesis. Third important variable is passenger class. The other two variables, sibsp (Number of Siblings/Spouses Aboard) and parch (Number of Parents/Children Aboard) seem to have little effect compared to the other variables.*


## Part 4 (optional): Spotify data: Which song features predict if a song is likely to be skipped?


We look again at the spotify data from practical 3
```{r message=FALSE, warning=FALSE}
load("../../data/spotify.Rdata")
```
and consider the binary outcome data if a song is likely to be skipped
```{r message=FALSE, warning=FALSE}
y_bin <- spotify.data$y_bin
table(y_bin)
```
As predictors we consider the variables given in the x_mat matrix. For more information on the features, please see https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/.

```{r message=FALSE, warning=FALSE}
x_mat <- spotify.data$x_mat
colnames(x_mat)
```

Question 4.1

Fit a random forest model that uses x_mat as predictors. Which song features are important to predict if a song is likely to be skipped?

```{r message=FALSE, warning=FALSE}
rf.out.bin <- randomForest(y = y_bin, x = x_mat %>% as.matrix())
varImpPlot(rf.out.bin, main = "")
```

*Reply: The most important variable is duration, most other variables are equally important except for age, which is the least important variable. *


Question 4.2

Contrast these findings with the results from the elastic net fit in practical 3 Question 4.4. How would you interpret the different findings?

*Reply: While elastic net optimises for prediction, it selects a model (set of variables) which is able to predict the outcome well. In contrast, variable importance in random forest is concerned with ranking the variables based on their importance in a specific model. In order to predict the sparse model may work fine, but in order to explain the relationship between music features and if the songs are skipped a much more complex picture including nearly all of the variables emerges.
So before doing the analysis you may want to think what is your motivation to do the analysis: Do you want to predict if a song is skipped (what spotify may want to optimise as a business concept) or do you want to understand what is the relationship between song features and response of the listeners (what an artist may want to know when composing music).*

